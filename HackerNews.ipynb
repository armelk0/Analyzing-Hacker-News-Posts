{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "In this project, we are going to analyze data from the website [Hacker News](https://news.ycombinator.com/) which is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/) where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit.\n",
    "The original dataset in this project can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts). \n",
    "<br> However, it has been reduced from almost 300,000 rows to approximatly 20,000 by removing all submissions that did not receive any comment, and then randomly sampling from the remaining submissions.\n",
    "<br> Below are descriptions of the columns:\n",
    "- id: The unique identifier from Hacker News for the post\n",
    "- title: The title of the post\n",
    "- url: The URL that the posts links to, if it the post has a URL\n",
    "- num_points: The number of points the post acquired, calculated as the - total number of upvotes minus the total number of downvotes\n",
    "- num_comments: The number of comments that were made on the post\n",
    "- author: The username of the person who submitted the post\n",
    "- created_at: The date and time at which the post was submitted\n",
    "\n",
    "In this analyze, we are going to focus on posts whose titles begin with either Ask HN or Show HN.\n",
    "<br> Users submit **Ask HN** posts to ask the Hacker News community a specific question. Below are a couple examples:\n",
    "\n",
    ">Ask HN: How to improve my personal website?\n",
    "<br> Ask HN: Am I the only one outraged by Twitter shutting down share counts?\n",
    "<br> Ask HN: Aby recent changes to CSS that broke mobile?\n",
    "\n",
    "Likewise, users submit **Show HN** posts to show the Hacker News community a project, product, or just generally something interesting. Below are a couple of examples:\n",
    "\n",
    ">Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development        Platform'\n",
    "<br> Show HN: Something pointless I made\n",
    "<br> Show HN: Shanhu.io, a programming playground powered by e8vm\n",
    "\n",
    "This analyze will compare these two types of posts to detemine :\n",
    "- Whether Ask HN or Show HN receive more comments on average?\n",
    "- Whether posts created at a particular time receive more comments on average?\n",
    "\n",
    "First, let's start by importing the libraries we need and reading the data set into a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "f = open('hacker_news.csv')\n",
    "reader = csv.reader(f)\n",
    "hn = list(reader)\n",
    "for row in hn[:5] :\n",
    "    print(row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print('\\n')\n",
    "for row in hn[:5] :\n",
    "    print(row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Ask HN, Show HN and Other posts\n",
    "Now let's filter our data and separate the **Ask HN**, **Show HN**, and the other posts by creating new lists of lists that will only contain those posts.\n",
    "<br> We will also determine how many of each type of post are contained in our data for analyzis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1744 Ask HN posts\n",
      "There are 1162 Show HN posts\n",
      "There are 17194 other posts\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "for row in hn :\n",
    "    title = (row[1].lower())\n",
    "    if title.startswith('ask hn') :\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn') :\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print('There are '+ str(len(ask_posts))+ ' Ask HN posts')\n",
    "print('There are '+ str(len(show_posts))+ ' Show HN posts')\n",
    "print('There are '+ str(len(other_posts))+ ' other posts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to notice is that there are far more **Ask HN** posts than **Show HN** posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Average number of comments for Show and Ask posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments for a Ask HN post is 14.038417431192661\n",
      "The average number of comments for a Show HN post is 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts :\n",
    "    n_comments = int(row[4])\n",
    "    total_ask_comments += n_comments\n",
    "total_show_comments = 0\n",
    "for row in show_posts :\n",
    "    n_comments = int(row[4])\n",
    "    total_show_comments += n_comments\n",
    "\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print('The average number of comments for a Ask HN post is', avg_ask_comments)\n",
    "print('The average number of comments for a Show HN post is', avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our findings, we can conclude that on average, a **Ask HN** post receives more comments than a **Show HN** post.\n",
    "<br> And like we noticed earlier, there are more **Ask HN** posts(about 1744) than **Show HN** posts(about 1162).\n",
    "<br> Because **Ask HN** posts receive more comments on average.\n",
    "We are going to focus on the **Ask HN** posts for the remaining parts of our analyzis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Ask Hn post created per Hours\n",
    "Now let's look at the time *Ask HN* posts where created at, to determine whether posts created at a certain time are more likely to attract comments. To achieve this, we are going to:\n",
    "- Calculate the amount of *Ask HN* posts created in each hour of the day, along with the number of comments received.\n",
    "- Calculate the average number of comments *Ask HN* posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['8/16/2016 9:55', 6], ['11/22/2015 13:43', 29], ['5/2/2016 10:14', 1], ['8/2/2016 14:20', 3], ['10/15/2015 16:38', 17]]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for row in ask_posts :\n",
    "    result_list.append([row[6], int(row[4])])\n",
    "print(result_list[:5])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour ={}\n",
    "for row in result_list :\n",
    "    n_comments = row[1]\n",
    "    date_created = dt.datetime.strptime(row[0], '%m/%d/%Y %H:%M')\n",
    "    hour = date_created.strftime('%H')\n",
    "    if hour not in counts_by_hour :\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = n_comments\n",
    "    else :\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += n_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above step, we comptuted the number of comments made for each hour and the number of posts created each hour.\n",
    "Now, we are going to compute the average number of comments that posts receive for each hour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['06', 9.022727272727273], ['19', 10.8], ['13', 14.741176470588234], ['22', 6.746478873239437], ['04', 7.170212765957447]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour :\n",
    "    avg_comments_by_hour = comments_by_hour[hour] / counts_by_hour[hour]\n",
    "    avg_by_hour.append([hour, avg_comments_by_hour])\n",
    "\n",
    "print(avg_by_hour[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make it easier to identify the hours with the most comments on average, let's sort the list of lists and print the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.022727272727273, '06'], [10.8, '19'], [14.741176470588234, '13'], [6.746478873239437, '22'], [7.170212765957447, '04'], [11.46, '17'], [7.985294117647059, '23'], [38.5948275862069, '15'], [10.08695652173913, '05'], [16.009174311926607, '21'], [11.383333333333333, '01'], [13.233644859813085, '14'], [8.127272727272727, '00'], [11.051724137931034, '11'], [7.852941176470588, '07'], [5.5777777777777775, '09'], [16.796296296296298, '16'], [23.810344827586206, '02'], [10.25, '08'], [21.525, '20'], [9.41095890410959, '12'], [13.440677966101696, '10'], [13.20183486238532, '18'], [7.796296296296297, '03']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour= []\n",
    "for row in avg_by_hour :\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post.\n",
      "02:00: 23.81 average comments per post.\n",
      "20:00: 21.52 average comments per post.\n",
      "16:00: 16.80 average comments per post.\n",
      "21:00: 16.01 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "for row in sorted_swap[:5] :\n",
    "    hour = dt.datetime.strptime(row[1], '%H')\n",
    "    hour = hour.strftime('%H:%M')\n",
    "    average_comments = row[0]\n",
    "    print('{}: {:.2f} average comments per post.'.format(hour, average_comments))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Our analzsis shows that, for a post to have the highest chance of receiving a comment, the post has to be created at **3pm**.\n",
    "<br> It is imposrtant to notice that the hours refered to in this analysis are in *Eastern Standard Time* (EST) or *US/Eastern timezone*.\n",
    "<br> We would need to convert them to account for different timezone/cities/countries/.\n",
    "For example, because I live in Dallas, Tx which is in *Central Daylight* Time or *US/Central*.\n",
    "For a post to have the highest chance of receiving a comment, a person in Dallas, Tx would need to post it at **2pm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:05\n"
     ]
    }
   ],
   "source": [
    "from pytz import timezone\n",
    "time = dt.datetime.strptime('15:00','%H:%M')\n",
    "time_w_zone = time.replace(tzinfo=timezone('US/Eastern'))\n",
    "time_in_dallas = time_w_zone.astimezone(timezone('US/Central'))\n",
    "print(time_in_dallas.strftime('%H:%M'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
